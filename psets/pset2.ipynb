{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2a9965",
   "metadata": {},
   "source": [
    "# 18.085 Problem Set 2\n",
    "\n",
    "Due Friday **March 3** at 1pm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8ae37",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "**(a)** The eigenvalues of a real *anti-Hermitian* matrix $A = -A^T$ must be \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_.   Derive this by considering $\\overline{x^T} A x$ for an eigenvector $Ax = \\lambda x$, and demonstrate it numerically by constructing a random anti-Hermitian matrix `A = randn(n,n); A = A - A'` in Julia and looking at its eigenvalues `using LinearAlgebra; eigvals(A)` for `n=4` and `n=5`.  (You might want to try the numerical experiment first if you aren't sure what the answer is.)\n",
    "\n",
    "**(b)** Suppose $A$ is a $3 \\times 3$ real-symmetric matrix with eigenvalues $\\lambda_1 = -2$, $\\lambda_2 = 3$, and $\\lambda_3 = -1$, with corresponding orthonormal eigenvectors $q_1, q_2, q_3$.  In terms of these quantities, give the (full) SVD of $A$.\n",
    "\n",
    "**(c)** Construct a random $5 \\times 3$ matrix `A = randn(5, 3)` and form a related *real-symmetric* matrix `B = [ 0I A; A' 0I ]`, corresponding to\n",
    "$$\n",
    "B = \\begin{pmatrix} 0 & A \\\\ A^T & 0 \\end{pmatrix} .\n",
    "$$\n",
    "Compare the eigenvalues of $B$ (`eigvals(B)`) to the singular values of $A$ (`svdvals(A)`).  What do you notice?  Explain it by using the SVD $A = U \\Sigma V^T$ to construct eigenvalues and eigenvectors of $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110f592",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "**(a)** For any $m \\times n$ real matrix $A$ and any real unitary $m \\times m$ matrix $Q_1$ and any real unitary $n \\times n$ matrix $Q_2$, show that $\\Vert A \\Vert$ = $\\Vert Q_1 A Q_2 \\Vert$ for the norms:\n",
    "$$\n",
    "\\Vert A \\Vert_2 = \\max_{x\\ne 0} \\frac{\\Vert A x \\Vert_2}{\\Vert x \\Vert_2}\\, , \\; \\; \\Vert A \\Vert_F = \\sqrt{\\text{tr}(A^T A) } \\, .\n",
    "$$\n",
    "Do *not* use the relationships of these norms to the singular values of $A$, from class; use only the definitions above.  (Hint: a change of variables may be useful for the first norm, and the cyclic property of the trace for the second.)\n",
    "\n",
    "**(b)** Using the full SVD $A = U \\Sigma V^T$ and the unitary invariance from part (a), show that $\\Vert A \\Vert_2 = \\sigma_1$ and $\\Vert A \\Vert_F = \\sqrt{\\sum_k \\sigma_k^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32250444",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Find a closest-rank-1 matrix (in the Frobenius norm, for example) to:\n",
    "\n",
    "**(a)** $A = \\begin{pmatrix} 0 & 3 \\\\ 2 & 0 \\end{pmatrix}$\n",
    "\n",
    "**(b)** $A = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix}$ (where $\\theta$ is some real number).\n",
    "\n",
    "You should be able to do your calculations completely by hand (it's not too hard, honest!), but of course you may use Julia to check your answers if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438a8e0",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "For an $m \\times m$ real-symmetric matrix $S = S^T$, we know that we have real eigenvalues $\\lambda_1,\\ldots,\\lambda_m$ and can find an orthonormal basis of eigenvectors $Q = \\begin{pmatrix} q_1 & \\cdots & q_m \\end{pmatrix}$.   So, we can write any vector $x \\in \\mathbb{R}^m$ as $x = Qc = q_1 c_1 + \\cdots q_m c_m$ for some coefficient $c$.\n",
    "\n",
    "**(a)** Show that $x^T x = c_1^2 + \\cdots + c_m^2$ and $x^T S x = \\lambda_1 c_1^2 + \\cdots + \\lambda_m c_m^2$.\n",
    "\n",
    "**(b)** Show that the **Rayleigh quotient**\n",
    "$$\n",
    "R(x) = \\frac{x^T S x}{x^T x}\n",
    "$$\n",
    "is *maximized* (over *any* possible $x \\ne 0$, not just eigenvectors) by $R(q_1) = \\lambda_1$.\n",
    "\n",
    "**(c)** If $A$ is any $m \\times n$ real matrix, we know that the squared singular values $\\sigma_i^2$ are the nonzero eigenvalues of $A^T A$.  Use this fact, combined with part (b), to give an alternative proof of why\n",
    "$$\n",
    "\\Vert A \\Vert_2 = \\max_{x\\ne 0} \\frac{\\Vert A x \\Vert_2}{\\Vert x \\Vert_2} = \\sigma_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac965b",
   "metadata": {},
   "source": [
    "## Problems 5, 6, etc: coming soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fca19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
